# ğŸ§  Prompt Engineering â€“ Study Notes

---

## ğŸ”¹ What is Prompt Engineering?

- Technique to design and structure **inputs (prompts)** for large language models (LLMs).
- Helps guide LLMs (like those in Amazon Bedrock) to generate **relevant, high-quality, and controlled outputs**.
- Crucial when using **foundation models** where model parameters are frozen and behavior is influenced by input prompts alone.

---

## âœï¸ Prompt Types

### âœ… Zero-shot Prompting
- No example provided.
- Just a clear instruction.
- **Example:**
  > "Translate this sentence to French: 'Good morning, how are you?'"

### âœ… One-shot Prompting
- One example given before the main input.
- Helps model understand the expected structure or behavior.
- **Example:**
Translate English to Tamil:
English: How are you?
Tamil: à®à®ªà¯à®ªà®Ÿà®¿ à®‡à®°à¯à®•à¯à®•à®¿à®±à¯€à®°à¯à®•à®³à¯?



### âœ… Few-shot Prompting
- Several examples provided to guide model behavior.
- Improves quality when task is nuanced.
- **Best used when model isnâ€™t performing well with zero-shot.**

---

## ğŸ› ï¸ Prompt Engineering Techniques

### ğŸ¯ Instruction Tuning
- Clearly instruct the model what to do.
- **Clarity matters**: use specific verbs (e.g., summarize, classify, translate, generate).

### ğŸ” Reframing Prompts
- Rewrite or rephrase a prompt to improve accuracy or creativity.

### ğŸ§© Chain-of-Thought Prompting (CoT)
- Encourage the model to **reason step-by-step** before reaching the answer.
- **Example:**
> "If Tom has 3 apples and gets 2 more, how many apples does he have now? Let's think step by step."

### ğŸ›ï¸ Role Assignment
- Assign a role to the model to add context.
- **Example:**
> "You are a nutritionist. Suggest a 1500-calorie meal plan for a vegetarian."

### ğŸ”„ Iterative Prompting
- Use multiple rounds of prompts and refine based on feedback or error.
- Often used in **RAG-based agents** and **agentic workflows**.

---

## ğŸ“ Sampling Control Techniques

| Parameter     | Purpose                                        |
|---------------|------------------------------------------------|
| **Temperature** | Controls randomness. Higher = more creative. Lower = more focused. |
| **Top-k**       | Chooses next token from top *k* candidates. |
| **Top-p (Nucleus)** | Chooses from smallest set of tokens whose total probability is â‰¥ *p*. |

**Tip:**
- Use lower temperature (e.g., 0.2â€“0.5) for predictable, consistent output.
- Use higher temperature (e.g., 0.8â€“1.0) for creativity or ideation tasks.

---

## ğŸ§ª Evaluation Tips

- Test prompts iteratively to check model responses.
- Avoid ambiguity and overly broad phrasing.
- Use **Guardrails** if prompt risks include bias, toxicity, or hallucination.

---

## ğŸ§  Best Practices

- Be **clear, concise, and contextual**.
- Prefer **positive prompts** (e.g., "Summarize this article") over vague ones ("What does this say?").
- When confused output appears, **break tasks into subtasks**.
- Use **system instructions** or **prefix roles** if model supports them.

---

## âœ… AWS AI Practitioner Exam Tips

- Prompt engineering is key to influencing output without retraining.
- Know difference between zero, one, and few-shot examples.
- Parameters like **temperature**, **top-p**, and **top-k** control generation style.
- Prompt engineering is **inference-time customization** (vs. fine-tuning which is model training).
